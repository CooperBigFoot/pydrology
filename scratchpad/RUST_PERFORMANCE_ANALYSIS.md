# Why Rust Is Slower Than Numba on HBV-Light and CemaNeige

## The Numbers

| Model | N | Numba (ms) | Rust (ms) | Ratio |
|-------|---|-----------|-----------|-------|
| GR2M | 12,000 | 0.59 | 0.40 | Rust 1.5x faster |
| GR6J | 3,650 | 0.52 | 0.27 | Rust 1.9x faster |
| HBV-Light | 36,500 | 1.20 | 2.82 | **Numba 2.4x faster** |
| GR6J-CemaNeige | 36,500 | 6.17 | 11.62 | **Numba 1.9x faster** |

Pure Rust (no PyO3) benchmarks confirm PyO3 overhead is negligible. The slowdown is in the Rust core itself.

GR2M and GR6J are fine. The problem is HBV-Light and CemaNeige.

---

## Root Causes

### 1. Missing Release Profile

`Cargo.toml` has no `[profile.release]` section. We're running with defaults:

| Setting | Current (default) | Optimal | Impact |
|---------|-------------------|---------|--------|
| `lto` | `false` | `true` | Without LTO, the compiler can't inline across crate boundaries. Process functions in `processes.rs`/`routing.rs` called from `run.rs` may not be inlined into the hot loop. |
| `codegen-units` | 16 | 1 | Code is split into 16 parallel chunks for faster compilation. The optimizer can't see across chunk boundaries, killing optimization opportunities. |
| `target-cpu` | `generic` | `native` | Generic codegen doesn't use Apple Silicon NEON SIMD. Numba always targets the host CPU. |

Numba gets all three for free: `@njit` compiles the entire function as a single LLVM IR unit targeting the native CPU.

### 2. Heap Allocation Per Timestep

`State.zone_states` is `Vec<[f64; 3]>` (heap-allocated). The `step()` function constructs a new `State` each call:

```rust
// run.rs:80 — inside step()
let new_state = State {
    zone_states: vec![[new_sp, new_lw, new_sm]],  // malloc for 3 floats!
    ...
};
```

At 36,500 timesteps, that's 36,500 malloc/free cycles to store 24 bytes. The `run()` function mutates state in place (good), but still pays for the `Vec` indirection on every `zone_states` access.

Numba keeps everything in registers/stack. Zero heap allocation.

### 3. FluxesTimeseries Layout (20 Scattered Vec Pushes)

The `#[derive(Fluxes)]` macro generates `FluxesTimeseries` with 20 separate `Vec<f64>` fields. Each `push()` does 20 individual `Vec::push` calls to 20 different heap locations:

```rust
// Generated by macro — conceptually:
fn push(&mut self, f: &Fluxes) {
    self.precip.push(f.precip);       // heap location A
    self.temp.push(f.temp);           // heap location B
    self.pet.push(f.pet);             // heap location C
    // ... 17 more scattered writes
}
```

This is cache-hostile. Each write touches a different cache line. Numba writes to pre-allocated contiguous numpy arrays with sequential access patterns.

### 4. No Inlining Hints on Process Functions

Small functions like `partition_precipitation`, `compute_melt`, `compute_recharge` in `processes.rs` have no `#[inline]` annotation. Without LTO, these may remain as function calls in the hot loop rather than being inlined. Each call = stack frame overhead + lost optimization context.

### 5. Why GR6J Doesn't Have This Problem

GR6J uses `State { production_store: f64, routing_store: f64, uh1_state: [f64; NH], uh2_state: [f64; 2*NH] }` — all fixed-size, stack-allocated. No `Vec`, no heap. The state size (63 elements) is known at compile time.

HBV-Light uses `Vec<[f64; 3]>` for `zone_states` because it supports variable zone counts. Even for the common single-zone case, this means heap allocation.

---

## Proposed Fixes

### Tier 1: Compiler Flags (No Code Changes)

Add to workspace `Cargo.toml`:

```toml
[profile.release]
lto = true
codegen-units = 1
```

Build with:

```bash
RUSTFLAGS="-C target-cpu=native" uv run maturin develop --release
```

**Expected impact:** 30-50% improvement. This is the single biggest lever.

### Tier 2: Eliminate Hot-Path Heap Allocation

Replace `Vec<[f64; 3]>` in `State` with a stack-friendly type for the common single-zone case. Options:

- **`SmallVec<[[f64; 3]; 4]>`** — stack-allocated up to 4 zones, spills to heap beyond that
- **Const generic** — `State<const N: usize>` with `zone_states: [[f64; 3]; N]`, monomorphized at compile time
- **Inline mutation** — `run()` already mutates state in place; ensure `step()` does too or is only used from Python (where allocation cost is noise)

**Expected impact:** 20-40% improvement for HBV single-zone runs.

### Tier 3: Contiguous Output Buffer

Replace 20 separate `Vec<f64>` in `FluxesTimeseries` with a single flat buffer:

```rust
struct FluxesTimeseries {
    data: Vec<f64>,      // single allocation, row-major
    n_timesteps: usize,
    n_fields: usize,     // 20
}
```

Or pre-allocate all 20 Vecs to exact capacity (the macro already does `with_capacity`, so the main cost is the 20 scattered writes per push, not reallocation).

**Expected impact:** 10-20% improvement from better cache locality.

### Tier 4: Inline Annotations

Add `#[inline]` to all small functions in:
- `hbv_light/processes.rs`
- `hbv_light/routing.rs`
- `cemaneige/processes.rs`

With LTO enabled (Tier 1) this matters less, but it's good practice and helps debug builds too.

**Expected impact:** 5-10% without LTO, marginal with LTO.

---

## Priority Order

1. **Tier 1 first** — zero risk, zero code changes, likely gets us to parity
2. **Benchmark after Tier 1** — if still slower, proceed to Tier 2
3. Tier 3 and 4 are refinements, unlikely to be needed if 1+2 close the gap

---

## Key Insight

Numba isn't faster because of LLVM magic. It's faster because `@njit` gives you all the "good defaults" for free: single compilation unit, native CPU target, zero heap allocation, full inlining. Rust can do all of this — we just haven't asked for it yet.

---

## Optimization Results (2026-02-14)

### Applied

| Tier | Optimization | Status |
|------|-------------|--------|
| 1 | `lto = true` + `codegen-units = 1` | Applied (earlier) |
| 1 | `target-cpu=native` via `.cargo/config.toml` | Applied |
| 1 | `strip = true` | Applied |
| 2 | SmallVec for HBV zone_states | Applied (earlier) |
| 2 | `write_unchecked` for FluxesTimeseries | Applied (earlier) |
| 2 | In-place UH convolution for HBV | Applied |
| 2 | `run_from_slices` delegates to optimized `run()` | Applied |
| 3 | Flat ZoneOutputs layout (HBV multi-zone) | Applied |
| 4 | `#[inline]` on GR6J `step()`, `convolve_uh()` | Applied |
| 4 | `#[inline]` on CemaNeige `cemaneige_layer_step()` | Applied |
| 4 | Indexed writes for CemaNeige layer fluxes | Applied |

### Remaining Gaps

- **HBV-Light (2.68 vs 1.20 ms):** The 20-field SoA FluxesTimeseries scatter writes dominate. Fixing this requires changing the `#[derive(Fluxes)]` macro to use a flat buffer layout. This is the highest-impact remaining change.
- **CemaNeige Python (11.41 vs 6.17 ms):** The PyO3 layer fluxes conversion (AoS→SoA transpose + `to_2d()` + `from_vec2()`) adds ~4.6 ms overhead. Fix: store layer fluxes as SoA in the Rust core or optimize the PyO3 conversion.
